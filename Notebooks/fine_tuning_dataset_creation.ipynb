{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92cdd96b-f149-4461-b37a-eb739116b726",
   "metadata": {},
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0726d6e8-ab8c-4df1-996c-267da30f9481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matlab/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/matlab/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "[nltk_data] Downloading package stopwords to /home/matlab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/matlab/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import chromadb\n",
    "import nltk\n",
    "import spacy\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import MistralConfig\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36ebd0-7216-437c-a93a-fe991fcac329",
   "metadata": {},
   "source": [
    "# Define helper functions and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61268505-8cf6-4268-9727-065c77af3dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    else:\n",
    "        return {\"text\":[]}\n",
    "\n",
    "def save_json(file_path, data):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, ensure_ascii=False)\n",
    "\n",
    "def extract_keywords(string):\n",
    "    # Extract keywords from the prompt\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(string)\n",
    "    keywords = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if not chunk.text.lower().strip() in nltk.corpus.stopwords.words('english'):\n",
    "            text = chunk.text\n",
    "            # Remove indirect articles\n",
    "            text = text.replace('a ', '').replace('an ', '').strip()\n",
    "            keywords.append(text)\n",
    "    # Convert keywords to their singular forms\n",
    "    keywords_singular = [lemmatizer.lemmatize(word) for word in keywords]\n",
    "    return keywords_singular\n",
    "\n",
    "def contains_keywords_filter(keywords, docs):\n",
    "    # Filter data by keywords\n",
    "    filtered_data = []\n",
    "    if len(keywords) > 0:\n",
    "        for doc in docs:\n",
    "            el = doc[0].page_content\n",
    "            if any(keyword in el for keyword in keywords):\n",
    "                filtered_data.append(doc)\n",
    "        return filtered_data\n",
    "    else:\n",
    "        return docs\n",
    "\n",
    "def format_docs_for_LLM(docs):\n",
    "    formated_documents = \"\"\n",
    "    for idx, doc in enumerate(docs):\n",
    "        page_content = \"ID: {}\\n\".format(idx)\n",
    "        page_content += \"Title: {}\\n\".format(doc[0].metadata['title'])\n",
    "        page_content += \"Content: \" + doc[0].page_content.replace(\"search_document: \", '', 1)\n",
    "        page_content += \"\\n\\n\"\n",
    "        formated_documents += page_content\n",
    "    return formated_documents\n",
    "\n",
    "\n",
    "def extract_titles_from_docs(docs):\n",
    "    titles = set()\n",
    "    for idx, doc in enumerate(docs):\n",
    "        titles.add(doc[0].metadata['title'])\n",
    "    return titles\n",
    "\n",
    "file_path = os.path.join('data', 'fine_tuning', 'data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc392ef9-60dc-44df-9285-51e536bbf650",
   "metadata": {},
   "source": [
    "# Prepare chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6dd772-2ddd-47e2-a542-6ea2325afabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 2.4.0.dev0, however, your version is 2.3.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "/home/matlab/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "        'trust_remote_code': True\n",
    "    }\n",
    ")\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path='chroma_data')\n",
    "langchain_vector_db = Chroma(client=chroma_client, embedding_function=embedding_model)\n",
    "\n",
    "def search_vector_db(query, vector_db, k=512):\n",
    "    query = 'search_query: ' + query\n",
    "    most_similar_docs = vector_db.similarity_search_with_relevance_scores(query, k=k)\n",
    "    return most_similar_docs\n",
    "\n",
    "# Peform initial search to load everything into memory\n",
    "search_vector_db(\"Sample query\", langchain_vector_db, k=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c541c6-1ff7-4db8-be96-9534b87e6f75",
   "metadata": {},
   "source": [
    "# Prepare the data and save it to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587488a7-20c4-4806-9d52-11ec67df78a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1efed968c54d898d103df9726d41b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", config=MistralConfig)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=256, device=0)\n",
    "LLM = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4f0944ae-e6ee-47e0-b1f6-f1d3c2cf6246",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a list of documents and a user prompt. Select up to 4 documents most useful for an LLM to solve the user prompt. Your output should consist of the IDs of selected documents (e.g. 0,3,7). If no documents are relevant, output 'None'. Do not solve the user prompt itself.\n",
      "\n",
      "user_prompt:\n",
      "Paraphrase the following sentence: The scientists conducted a rigorous experiment\n",
      "\n",
      "Documents:\n",
      "ID: 0\n",
      "Title: Inductivism\n",
      "Content: 1962, was first published in the International Encyclopedia of Unified Science—a project begun by logical positivists—and somehow, at last, unified the empirical sciences by withdrawing the physics model, and scrutinizing them via history and sociology. Lacking such heavy use of mathematics and logic's formal language—an approach introduced in the Vienna Circle's Rudolf Carnap in the 1920s—Kuhn's book, powerful and persuasive, used in natural language open to laypersons. Structure explains science as puzzlesolving toward a vision projected by the \"ruling class\" of a scientific specialty's community, whose \"unwritten rulebook\" dictates acceptable problems and solutions, altogether normal science.Lipton, \"Truth about science\", Philos Trans R Soc Lond B Biol Sci, 2005;360(1458):1259–69. The scientists reinterpret ambiguous data, discard anomalous data, and try to stuff nature into the box of their shared paradigm—a theoretical matrix or fundamental view of nature—until compatible data become scarce, anomalies accumulate, and scientific \"crisis\" ensues. Newly training, some young scientists defect to revolutionary science, which, simultaneously explaining both the normal data and the anomalous data, resolves the crisis by setting a new \"exemplar\" that contradicts normal science. Kuhn explains that rival paradigms, having incompatible languages, are incommensurable. Trying to resolve conflict, scientists talk past each other, as even direct observations—for example, that the Sun is \"rising\"—get fundamentally conflicting interpretations. Some working scientists convert by a perspectival shift that—to their astonishment—snaps the new paradigm, suddenly obvious, into view. Others, never attaining such gestalt switch, remain holdouts, committed for life to the old paradigm. One by one, holdouts die. Thus, the new exemplar—the new, unwritten rulebook—settles in the new normal science. The old theoretical matrix becomes so shrouded by the meanings of terms in the new theoretical\n",
      "\n",
      "ID: 1\n",
      "Title: The Afterlife Experiments\n",
      "Content: But this time, the experimenter relayed the responses to \"yes/no\" questions instead of the sitter directly responding “yes/no” *Instead of each sitter rating the accuracy of statements from their own readings only, all four participating sitters rated the accuracy of all statements Schwartz notes that sitters rated the accuracy of the statements made by the mediums during these experiments, as in the previous experiments. The data from these experiments are not detailed in the book. Instead, he includes a list of alleged hits by John Edward that he describes as “dazzle shots.” ==Reception and analyses== There was initial positive reception upon release of the book and the results it detailed, primarily from the mediumship community and the media at large. Some noted the application of the scientific method to the unique subject of life after death. Others praised the experiments detailed in the book for their precision, detail, and the compelling nature of the results as presented. The accuracy rate of the mediums was often cited as 85% and above. Widespread critiques of Schwartz’s experimental methodology and analysis of results were noted in several subsequently published articles by, among others, Ray Hyman, Richard Wiseman, and James Randi. Prior to the conduction of the studies, the James Randi Educational Foundation (JREF) suggested a sufficiently rigorous experimental design to Schwartz that was believed would result in scientifically sound results. Schwartz did not utilize these designs in his experiments. In general, it was thought that the opportunity for mediums to implement cold reading techniques was ubiquitous, despite the design of the studies. More specifically, criticisms included: *Judging bias: Statements made by mediums generally vary in specificity and subjectivity, and are then judged subjectively by the sitters to be accurate or not. Sitters may be motivated\n",
      "\n",
      "ID: 2\n",
      "Title: Pseudoscience\n",
      "Content: is, if it is possible to conceive of an observation or an argument that negates them. Popper used astrology and psychoanalysis as examples of pseudoscience and Einstein's theory of relativity as an example of science. He subdivided nonscience into philosophical, mathematical, mythological, religious and metaphysical formulations on one hand, and pseudoscientific formulations on the other. Another example which shows the distinct need for a claim to be falsifiable was stated in Carl Sagan's publication The Demon-Haunted World when he discusses an invisible dragon that he has in his garage. The point is made that there is no physical test to refute the claim of the presence of this dragon. Whatever test one thinks can be devised, there is a reason why it does not apply to the invisible dragon, so one can never prove that the initial claim is wrong. Sagan concludes; \"Now, what's the difference between an invisible, incorporeal, floating dragon who spits heatless fire and no dragon at all?\". He states that \"your inability to invalidate my hypothesis is not at all the same thing as proving it true\", once again explaining that even if such a claim were true, it would be outside the realm of scientific inquiry. ===Mertonian norms=== During 1942, Robert K. Merton identified a set of five \"norms\" which characterize real science. If any of the norms were violated, Merton considered the enterprise to be nonscience. These are not broadly accepted by the scientific community. His norms were: * Originality: The tests and research done must present something new to the scientific community. * Detachment: The scientists' reasons for practicing this science must be simply for the expansion of their knowledge. The scientists should not have personal reasons to expect certain results. *\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"\"\"Paraphrase the following sentence: The scientists conducted a rigorous experiment\"\"\"\n",
    "docs_with_score = search_vector_db(user_prompt, langchain_vector_db)\n",
    "\n",
    "keywords = extract_keywords(user_prompt)\n",
    "filtered_docs = contains_keywords_filter(keywords, docs_with_score)\n",
    "filtered_docs = filtered_docs[:8]\n",
    "documents = format_docs_for_LLM(filtered_docs)\n",
    "\n",
    "prompt_template = \"\"\"<s>[INST] Below is a list of documents. Return up to 4 IDs of documents most useful for solving the user_prompt. If no documents are relevant, output -1. {format}. \n",
    "\n",
    "<documents>\n",
    "{documents}\n",
    "</documents>\n",
    "\n",
    "user_prompt: {user_prompt}\n",
    "\n",
    "[/INST]IDs: \"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "chain = prompt | LLM\n",
    "    \n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "#response = chain.invoke({'format':output_parser.get_format_instructions(), 'documents': documents, 'user_prompt': user_prompt})\n",
    "print(\"Below is a list of documents and a user prompt. Select up to 4 documents most useful for an LLM to solve the user prompt. Your output should consist of the IDs of selected documents (e.g. 0,3,7). If no documents are relevant, output 'None'. Do not solve the user prompt itself.\\n\")\n",
    "print('user_prompt:')\n",
    "print(user_prompt)\n",
    "print('')\n",
    "print('Documents:')\n",
    "print(documents)\n",
    "#print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daed805-3fe0-42ab-b3f2-45b3e1676ea0",
   "metadata": {},
   "source": [
    "# Save to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "76afc836-b58f-45bd-b259-7cc6ff3eb45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_prompt_template = \"\"\"<s>[INST] Below is a list of documents. Return up to 4 IDs of documents most useful for solving the user_prompt. {}.\n",
    "\n",
    "<documents>\n",
    "{}\n",
    "</documents>\n",
    "\n",
    "user_prompt: {}\n",
    "\n",
    "[/INST] {}\"\"\"\n",
    "\n",
    "desired_output = \"\"\"\"\"\"\n",
    "desired_output += '</s>'\n",
    "json_prompt_template = json_prompt_template.format(output_parser.get_format_instructions(), documents, user_prompt, desired_output)\n",
    "\n",
    "\n",
    "# Add new data to the json file\n",
    "data = load_json(file_path)\n",
    "data[\"text\"].extend([json_prompt_template])\n",
    "save_json(file_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b1cfd-b759-4491-9e2f-ca6a2d02f998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
