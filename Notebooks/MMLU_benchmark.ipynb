{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d63906b-83d3-40ed-8a40-cc92fe427500",
   "metadata": {},
   "source": [
    "# Benchmark config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4a3829-e8bb-469b-9057-dd212590b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_enabled = True\n",
    "quantization = '4bit' # Valid values: None, '8bit', '4bit'\n",
    "results_file_name = 'rag_4bit_10_shot.csv'\n",
    "\n",
    "RAGPipeline_module_dir = '/home/matlab/data/Dominik/app'\n",
    "rag_adapter_path = './fine_tuning/fine_tuned_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e504e6-c31e-49f7-bef3-7fda89f0d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import MistralConfig, BitsAndBytesConfig\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if rag_enabled:\n",
    "    sys.path.append(RAGPipeline_module_dir)\n",
    "    from RAGPipeline import RAGPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5d0be5-c554-4862-8633-6a3614379544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sample_questions(sample_questions):\n",
    "    letter_answers = ['A', 'B', 'C', 'D']\n",
    "    sample_questions_dicts = []\n",
    "    for idx in range(len(sample_questions['question'])):\n",
    "        sample_question_dict = {}\n",
    "        sample_question_dict['question'] = sample_questions['question'][idx]\n",
    "        sample_question_dict['answer_A'] = sample_questions['choices'][idx][0]\n",
    "        sample_question_dict['answer_B'] = sample_questions['choices'][idx][1]\n",
    "        sample_question_dict['answer_C'] = sample_questions['choices'][idx][2]\n",
    "        sample_question_dict['answer_D'] = sample_questions['choices'][idx][3]\n",
    "        sample_question_dict['correct_answer'] = letter_answers[sample_questions['answer'][idx]]\n",
    "        sample_questions_dicts.append(sample_question_dict)\n",
    "    return sample_questions_dicts\n",
    "\n",
    "\n",
    "def prepare_prompt(domain, sample_questions, question, question_context = '\\nNone\\n'):\n",
    "    domain = re.sub(\"_\", \" \", domain)\n",
    "    # Prompt begining\n",
    "    prompt = \"<s>[INST] The following are multiple choice questions (with answers) about {} with optional, helpful context for the last question.\".format(domain)\n",
    "    prompt += \"\\n\\n<context>{}</context>\\n\".format(question_context)\n",
    "    question_template = \"\\nQuestion: {}\\nA: {}\\nB: {}\\nC: {}\\nD: {}\\nAnswer: {}\"\n",
    "    # Sample questions with answers\n",
    "    for example in sample_questions:\n",
    "        example_question = question_template.format(\n",
    "            example['question'],\n",
    "            example['answer_A'],\n",
    "            example['answer_B'],\n",
    "            example['answer_C'],\n",
    "            example['answer_D'],\n",
    "            example['correct_answer']\n",
    "        )\n",
    "        prompt += example_question + '\\n'\n",
    "    # Question that the model must answer\n",
    "    question = question_template.format(\n",
    "            question['question'],\n",
    "            question['choices'][0],\n",
    "            question['choices'][1],\n",
    "            question['choices'][2],\n",
    "            question['choices'][3],\n",
    "            ''\n",
    "        )\n",
    "    prompt += question + '[/INST]'\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def convert_answer(answer):\n",
    "    \"\"\"\n",
    "    Convert the model's answer (A, B, C or D) to a numerical equivalent in the MMLU\n",
    "    benchmark\n",
    "\n",
    "    Parameters:\n",
    "    answer (str): the model's answer (only the first character matters)\n",
    "\n",
    "    Returns:\n",
    "    (int): numerical equivalent to the answer in the MMLU dataset\n",
    "    \"\"\"\n",
    "    if len(answer) == 0:\n",
    "        return 4 # No answer doesn't meet requirements\n",
    "    elif answer[0] == 'A' or answer[0] == 'a':\n",
    "        return 0\n",
    "    elif answer[0] == 'B' or answer[0] == 'b':\n",
    "        return 1\n",
    "    elif answer[0] == 'C' or answer[0] == 'c':\n",
    "        return 2\n",
    "    elif answer[0] == 'D' or answer[0] == 'd':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4 # Answer doesn't meet stated requirements\n",
    "\n",
    "def sanitize_IDs(model_output, ids_max_count=4, max_id=7):\n",
    "    sanitized_IDs = []\n",
    "    # If the model didn't output anything, return an empty list\n",
    "    if len(model_output) == 0:\n",
    "        return []\n",
    "    for idx, el in enumerate(model_output):\n",
    "        # print(el[0])\n",
    "        # Break the loop after reaching idx_max_count of if el\n",
    "        # is an empty string\n",
    "        if idx == ids_max_count or el == '':\n",
    "            break\n",
    "        # If there's a -1, then non of the ids are relevant - return an empty list\n",
    "        elif el[0].isdigit() and int(el[0]) == -1:\n",
    "            return []\n",
    "        elif el[0].isdigit() and int(el[0]) >= 0 and int(el[0]) <= max_id:\n",
    "            sanitized_IDs.append(int(el[0]))\n",
    "        else:\n",
    "            break\n",
    "    return sanitized_IDs\n",
    "\n",
    "def select_docs_by_id(documents_raw, ids):\n",
    "    documents_selected = []\n",
    "    for doc in documents_raw:\n",
    "        if doc[0].metadata['ID'] in ids:\n",
    "            documents_selected.append(doc)\n",
    "    return documents_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33970717-4ce9-458a-8892-c760edb593aa",
   "metadata": {},
   "source": [
    "# Load the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5e65d5-f1f5-4419-83f4-c72dc55aa30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matlab/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd34745ff5064c9b9e2be14cccbe37de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with 4-bit quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG pipeline loaded\n"
     ]
    }
   ],
   "source": [
    "base_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "# Choose quantization type\n",
    "if quantization == '8bit':\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(base_model, config=MistralConfig, quantization_config=bnb_config, device_map='cuda')\n",
    "    print('Model loaded with 8-bit quantization')\n",
    "elif quantization == '4bit':\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(base_model, config=MistralConfig, quantization_config=bnb_config, device_map='cuda')\n",
    "    print('Model loaded with 4-bit quantization')\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(base_model, config=MistralConfig, device_map='cuda')\n",
    "    print('Model loaded with no quantization')\n",
    "\n",
    "# Load the RAG adapter if RAG is enabled\n",
    "if rag_enabled:\n",
    "    model.load_adapter(rag_adapter_path, adapter_name='rag_adapter')\n",
    "    model.set_adapter('rag_adapter')\n",
    "    model.disable_adapters()\n",
    "    rag_pipeline = RAGPipeline()\n",
    "    print('RAG pipeline loaded')\n",
    "    rag_prompt_template = \"\"\"<s>[INST] Below is a list of documents. Return up to 4 IDs of documents most useful for solving the user_prompt. If no documents are relevant, output -1. {format}. \n",
    "    \n",
    "<documents>\n",
    "{documents}\n",
    "</documents>\n",
    "\n",
    "user_prompt: {user_prompt}\n",
    "\n",
    "[/INST]IDs: \"\"\"\n",
    "    output_parser = CommaSeparatedListOutputParser()\n",
    "else:\n",
    "    print('RAG disabled')\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", config=MistralConfig)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "# pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, pad_token_id=tokenizer.eos_token_id, max_new_tokens=1, device=0)\n",
    "# pipe.tokenizer.pad_token_id = model.config.eos_token_id\n",
    "# LLM = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# prompt_template = \"\"\"<s>[INST] Your objective is to select the right answer for the question stated below.\n",
    "# If question 'A' is the correct answer, output 'A'; if 'B' is the correct answer, output 'B', and so on.\n",
    "# Do not explain or justify your answer. Your output must be a single letter: 'A', 'B', 'C', or 'D'.\n",
    "# Question: {question}\n",
    "# A: {answer_A}\n",
    "# B: {answer_B}\n",
    "# C: {answer_C}\n",
    "# D: {answer_D}\n",
    "# Your answer: [/INST]\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = PromptTemplate.from_template(prompt_template)\n",
    "# chain = prompt | LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6120d49b-c5cd-4d0d-be09-f97e5057cd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8f027c8e0b40d2b21c2f0b7d81097f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] The following are multiple choice questions (with answers) about abstract algebra with optional, helpful context for the last question.\n",
      "\n",
      "<context>\n",
      "Title: Field extension\n",
      "\\right \\\\}, is an extension field of \\Q, also clearly a simple extension. The degree is 2 because \\left\\\\{1, \\sqrt{2}\\right\\\\} can serve as a basis. The field :\\begin{align} \\Q\\left(\\sqrt{2}, \\sqrt{3}\\right) &= \\Q \\left(\\sqrt{2}\\right) \\left(\\sqrt{3}\\right) \\\\\\ &= \\left\\\\{ a+b\\sqrt{3} \\mid a,b \\in \\Q\\left(\\sqrt{2}\\right) \\right\\\\} \\\\\\ &= \\left\\\\{ a + b \\sqrt{2} + c\\sqrt{3} + d\\sqrt{6} \\mid a,b,c, d \\in \\Q \\right\\\\}, \\end{align} is an extension field of both \\Q(\\sqrt{2}) and \\Q, of degree 2 and 4 respectively. It is also a simple extension, as one can show that :\\begin{align} \\Q(\\sqrt{2}, \\sqrt{3}) &= \\Q (\\sqrt{2} + \\sqrt{3}) \\\\\\ &= \\left \\\\{ a + b (\\sqrt{2} + \\sqrt{3}) + c (\\sqrt{2} + \\sqrt{3})^2 + d(\\sqrt{2} + \\sqrt{3})^3 \\mid a,b,c, d \\in \\Q\\right\\\\}. \\end{align} Finite extensions of \\Q are also called algebraic number fields and are important in number theory. Another extension field of the rationals, which is also important in number theory, although not a finite extension, is the field of p-adic numbers \\Q_p for a prime number p. It is common to construct an extension field of a given field K as a quotient ring of the polynomial ring K[X] in order to \"create\" a root for a given polynomial f(X). Suppose for instance that K does not contain any element x with x2 = −1. Then the polynomial X^2+1 is irreducible in K[X], consequently the ideal generated by this polynomial is maximal, and L = K[X]/(X^2+1) is an extension field of K which does contain an\n",
      "\n",
      "Title: Degree of a field extension\n",
      "text: In mathematics, more specifically field theory, the degree of a field extension is a rough measure of the \"size\" of the field extension. The concept plays an important role in many parts of mathematics, including algebra and number theory -- indeed in any area where fields appear prominently. == Definition and notation == Suppose that E/F is a field extension. Then E may be considered as a vector space over F (the field of scalars). The dimension of this vector space is called the degree of the field extension, and it is denoted by [E:F]. The degree may be finite or infinite, the field being called a finite extension or infinite extension accordingly. An extension E/F is also sometimes said to be simply finite if it is a finite extension; this should not be confused with the fields themselves being finite fields (fields with finitely many elements). The degree should not be confused with the transcendence degree of a field; for example, the field Q(X) of rational functions has infinite degree over Q, but transcendence degree only equal to 1. == The multiplicativity formula for degrees == Given three fields arranged in a tower, say K a subfield of L which is in turn a subfield of M, there is a simple relation between the degrees of the three extensions L/K, M/L and M/K: : [M:K] = [M:L] \\cdot [L:K]. In other words, the degree going from the \"bottom\" to the \"top\" field is just the product of the degrees going from the \"bottom\" to the \"middle\" and then from the \"middle\" to the \"top\". It is quite analogous to Lagrange's theorem in group theory, which relates the order of a group to the order and index\n",
      "\n",
      "Title: Galois group\n",
      "i}{3} \\right ) \\sqrt[3]{2} and \\exp \\left (\\tfrac{4\\pi i}{3} \\right ) \\sqrt[3]{2}, are missing from the extension—in other words is not a splitting field. === Finite abelian groups === The Galois group \\operatorname{Gal}(\\Complex/\\R) has two elements, the identity automorphism and the complex conjugation automorphism.. ==== Quadratic extensions ==== The degree two field extension \\Q(\\sqrt{2})/\\Q has the Galois group \\operatorname{Gal}(\\Q(\\sqrt{2})/\\Q) with two elements, the identity automorphism and the automorphism \\sigma which exchanges \\sqrt2 and -\\sqrt2. This example generalizes for a prime number p \\in \\N. ==== Product of quadratic extensions ==== Using the lattice structure of Galois groups, for non-equal prime numbers p_1, \\ldots, p_k the Galois group of \\Q \\left (\\sqrt{p_1},\\ldots, \\sqrt{p_k} \\right)/\\Q is :\\operatorname{Gal} \\left (\\Q(\\sqrt{p_1},\\ldots, \\sqrt{p_k})/\\Q \\right ) \\cong \\operatorname{Gal}\\left (\\Q(\\sqrt{p_1})/\\Q \\right )\\times \\cdots \\times \\operatorname{Gal} \\left (\\Q(\\sqrt{p_k})/\\Q \\right ) \\cong (\\Z/2\\Z)^k ==== Cyclotomic extensions ==== Another useful class of examples comes from the splitting fields of cyclotomic polynomials. These are polynomials \\Phi_n defined as :\\Phi_n(x) = \\prod_{\\begin{matrix} 1 \\leq k \\leq n \\\\\\ \\gcd(k,n) = 1\\end{matrix}} \\left(x-e^{\\frac{2ik\\pi}{n}} \\right) whose degree is \\phi(n), Euler's totient function at n. Then, the splitting field over \\Q is \\Q(\\zeta_n) and has automorphisms \\sigma_a sending \\zeta_n \\mapsto \\zeta_n^a for 1 \\leq a < n relatively prime to n. Since the degree of the field is equal to the degree of the polynomial, these automorphisms generate the Galois group. If n =\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: Statement 1 | If a finite group has order n then the group contains a subgroup of order d for every positive divisor d of n. Statement 2 | If a belongs to a finite group then |a| divides |G|.\n",
      "A: True, True\n",
      "B: False, False\n",
      "C: True, False\n",
      "D: False, True\n",
      "Answer: D\n",
      "\n",
      "Question: Find all cosets of the subgroup 4Z of 2Z.\n",
      "A: 4Z\n",
      "B: 4Z, 2 + 4Z\n",
      "C: 2Z\n",
      "D: Z\n",
      "Answer: B\n",
      "\n",
      "Question: Which of the following statements is true?\n",
      "A: Every equivalence relation is a partial-ordering relation.\n",
      "B: Number of relations form A = {x, y, z} to B= (1, 2), is 64.\n",
      "C: Empty relation _ is reflexive\n",
      "D: Properties of a relation being symmetric and being un-symmetric are negative of each other.\n",
      "Answer: B\n",
      "\n",
      "Question: Find the maximum possible order for an element of S_n for n = 6.\n",
      "A: 6\n",
      "B: 12\n",
      "C: 30\n",
      "D: 105\n",
      "Answer: A\n",
      "\n",
      "Question: Statement 1 | Q is an extension field of Z_2. Statement 2 | Every non-constant polynomial over a field has a zero in some extension field.\n",
      "A: True, True\n",
      "B: False, False\n",
      "C: True, False\n",
      "D: False, True\n",
      "Answer: D\n",
      "\n",
      "Question: Statement 1 | If H is a subgroup of G and a belongs to G then aH is a subgroup of G if and only if a is in H. Statement 2 | If H is a subgroup of G and a and b belong to G then aH = bH if and only if ab is in H.\n",
      "A: True, True\n",
      "B: False, False\n",
      "C: True, False\n",
      "D: False, True\n",
      "Answer: C\n",
      "\n",
      "Question: Find all zeros in the indicated finite field of the given polynomial with coefficients in that field. x^2 + 1 in Z_2\n",
      "A: 0\n",
      "B: 1\n",
      "C: 0,1\n",
      "D: 2\n",
      "Answer: B\n",
      "\n",
      "Question: Find the number of elements in the indicated cyclic group: The cyclic subgroup of Z_30 generated by 25.\n",
      "A: 25\n",
      "B: 5\n",
      "C: 6\n",
      "D: 30\n",
      "Answer: C\n",
      "\n",
      "Question: The element (4, 2) of Z_12 x Z_8 has order\n",
      "A: 4\n",
      "B: 8\n",
      "C: 12\n",
      "D: 6\n",
      "Answer: C\n",
      "\n",
      "Question: Statement 1 | Every ideal in a ring is a subring of the ring. Statement 2 | Every subring of every ring is an ideal of the ring.\n",
      "A: True, True\n",
      "B: False, False\n",
      "C: True, False\n",
      "D: False, True\n",
      "Answer: C\n",
      "\n",
      "Question: Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q.\n",
      "A: 0\n",
      "B: 4\n",
      "C: 2\n",
      "D: 6\n",
      "Answer: [/INST]\n",
      "<s>[INST] The following are multiple choice questions (with answers) about abstract algebra with optional, helpful context for the last question.\n",
      "\n",
      "<context>\n",
      "Title: Merge sort\n",
      "are determined with binary search and thus the S_i are further partitioned into p subsequences S_{i,1}, ..., S_{i,p} with S_{i,j} := \\\\{x \\in S_i | rank(v_{j-1}) < rank(x) \\le rank(v_j)\\\\}. Furthermore, the elements of S_{1,i}, ..., S_{p,i} are assigned to processor i, means all elements between rank (i-1) \\frac{n}{p} and rank i \\frac{n}{p}, which are distributed over all S_i. Thus, each processor receives a sequence of sorted sequences. The fact that the rank k of the splitter elements v_i was chosen globally, provides two important properties: On the one hand, k was chosen so that each processor can still operate on n/p elements after assignment. The algorithm is perfectly load-balanced. On the other hand, all elements on processor i are less than or equal to all elements on processor i+1. Hence, each processor performs the p-way merge locally and thus obtains a sorted sequence from its sub-sequences. Because of the second property, no further p-way-merge has to be performed, the results only have to be put together in the order of the processor number. ==== Multi-sequence selection ==== In its simplest form, given p sorted sequences S_1, ..., S_p distributed evenly on p processors and a rank k, the task is to find an element x with a global rank k in the union of the sequences. Hence, this can be used to divide each S_i in two parts at a splitter index l_i, where the lower part contains only elements which are smaller than x, while the elements bigger than x are located in the upper part. The presented sequential algorithm returns the indices of the splits in each sequence, e.g. the indices\n",
      "\n",
      "Title: Cantor's first set theory article\n",
      "all of the numbers in P. The base case starts with the interval (a, b). Since P is dense in [a, b], there are infinitely many numbers of P in (a, b). Let xk1 be the number with the least index and xk2 be the number with the next larger index, and let a1 be the smaller and b1 be the larger of these two numbers. Then, k1 < k2, , and (a1, b1) is a proper subinterval of (a, b). Also, for m ≤ k2 since these xm are the endpoints of (a1, b1). Repeating the above proof with the interval (a1, b1) produces k3, k4, a2, b2 such that and and for m ≤ k4. The recursive step starts with the interval , the inequalities and , and the fact that the interval excludes the first 2n–2 members of the sequence is, for m ≤ k2n–2. Since P is dense in [a, b], there are infinitely many numbers of P in . Let xk2n–1 be the number with the least index and xk2n be the number with the next larger index, and let an be the smaller and bn be the larger of these two numbers. Then, k2n–1 < k2n, , and (an, bn) is a proper subinterval of . Combining these inequalities with the ones for step n–1 of the recursion produces and . Also, for m = k2n–1 and m = k2n since these xm are the endpoints of (an, bn). This together with excluding the first 2n–2 members of sequence P implies that the interval (an, bn) excludes the first 2n members of is, for m ≤ k2n. Therefore, for all n, since n ≤ k2n.\n",
      "\n",
      "Title: Congruence subgroup\n",
      "index in the stabiliser of a finite-index sub-lattice in \\Z^d. === Congruence subgroups === Let \\Gamma be an arithmetic group: for simplicity it is better to suppose that \\Gamma \\subset \\mathrm{GL}_n(\\Z). As in the case of \\mathrm{SL}_2(\\Z) there are reduction morphisms \\pi_n: \\Gamma \\to \\mathrm{GL}_d(\\Z/n\\Z). We can define a principal congruence subgroup of \\Gamma to be the kernel of \\pi_n (which may a priori depend on the representation \\rho), and a congruence subgroup of \\Gamma to be any subgroup which contains a principal congruence subgroup (a notion which does not depend on a representation). They are subgroups of finite index which correspond to the subgroups of the finite groups \\pi_n(\\Gamma), and the level is defined. === Examples === The principal congruence subgroups of \\mathrm{SL}_d(\\Z ) are the subgroups \\Gamma(n) given by: :\\Gamma(n) = \\left\\\\{(a_{ij}) \\in \\mathrm{SL}_d(\\Z ): \\forall i \\, a_{ii} \\equiv 1 \\pmod n, \\, \\forall i eq j \\, a_{ij} \\equiv 0 \\pmod n \\right\\\\} the congruence subgroups then correspond to the subgroups of \\mathrm{SL}_d(\\Z/n\\Z ). Another example of arithmetic group is given by the groups \\mathrm{SL}_2(O) where O is the ring of integers in a number field, for example O = \\Z[\\sqrt 2]. Then if \\mathfrak p is a prime ideal dividing a rational prime p the subgroups \\Gamma(\\mathfrak p) which is the kernel of the reduction map mod \\mathfrak p is a congruence subgroup since it contains the principal congruence subgroup defined by reduction modulo p. Yet another arithmetic group is the Siegel modular groups \\mathrm{Sp}_{2g}(\\Z), defined by: :\\mathrm{Sp}_{2g}(\\Z)\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: Statement 1 | If a finite group has order n then the group contains a subgroup of order d for every positive divisor d of n. Statement 2 | If a belongs to a finite group then |a| divides |G|.\n",
      "A: True, True\n",
      "B: False, False\n",
      "C: True, False\n",
      "D: False, True\n",
      "Answer: D\n",
      "\n",
      "Question: Find all cosets of the subgroup 4Z of 2Z.\n",
      "A: 4Z\n",
      "B: 4Z, 2 + 4Z\n",
      "C: 2Z\n",
      "D: Z\n",
      "Answer: B\n",
      "\n",
      "Question: Which of the following statements is true?\n",
      "A: Every equivalence relation is a partial-ordering relation.\n",
      "B: Number of relations form A = {x, y, z} to B= (1, 2), is 64.\n",
      "C: Empty relation _ is reflexive\n",
      "D: Properties of a relation being symmetric and being un-symmetric are negative of each other.\n",
      "Answer: B\n",
      "\n",
      "Question: Find the maximum possible order for an element of S_n for n = 6.\n",
      "A: 6\n",
      "B: 12\n",
      "C: 30\n",
      "D: 105\n",
      "Answer: A\n",
      "\n",
      "Question: Statement 1 | Q is an extension field of Z_2. Statement 2 | Every non-constant polynomial over a field has a zero in some extension field.\n",
      "A: True, True\n",
      "B: False, False\n",
      "C: True, False\n",
      "D: False, True\n",
      "Answer: D\n",
      "\n",
      "Question: Statement 1 | If H is a subgroup of G and a belongs to G then aH is a subgroup of G if and only if a is in H. Statement 2 | If H is a subgroup of G and a and b belong to G then aH = bH if and only if ab is in H.\n",
      "A: True, True\n",
      "B: False, False\n",
      "C: True, False\n",
      "D: False, True\n",
      "Answer: C\n",
      "\n",
      "Question: Find all zeros in the indicated finite field of the given polynomial with coefficients in that field. x^2 + 1 in Z_2\n",
      "A: 0\n",
      "B: 1\n",
      "C: 0,1\n",
      "D: 2\n",
      "Answer: B\n",
      "\n",
      "Question: Find the number of elements in the indicated cyclic group: The cyclic subgroup of Z_30 generated by 25.\n",
      "A: 25\n",
      "B: 5\n",
      "C: 6\n",
      "D: 30\n",
      "Answer: C\n",
      "\n",
      "Question: The element (4, 2) of Z_12 x Z_8 has order\n",
      "A: 4\n",
      "B: 8\n",
      "C: 12\n",
      "D: 6\n",
      "Answer: C\n",
      "\n",
      "Question: Statement 1 | Every ideal in a ring is a subring of the ring. Statement 2 | Every subring of every ring is an ideal of the ring.\n",
      "A: True, True\n",
      "B: False, False\n",
      "C: True, False\n",
      "D: False, True\n",
      "Answer: C\n",
      "\n",
      "Question: Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.\n",
      "A: 8\n",
      "B: 2\n",
      "C: 24\n",
      "D: 120\n",
      "Answer: [/INST]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     26\u001b[0m prompt \u001b[38;5;241m=\u001b[39m question[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 27\u001b[0m documents_raw \u001b[38;5;241m=\u001b[39m \u001b[43mrag_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_relevant_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(documents_raw) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     29\u001b[0m     documents_llm \u001b[38;5;241m=\u001b[39m rag_pipeline\u001b[38;5;241m.\u001b[39mformat_docs_for_LLM(documents_raw)\n",
      "File \u001b[0;32m~/data/Dominik/app/RAGPipeline.py:91\u001b[0m, in \u001b[0;36mRAGPipeline.retrieve_relevant_data\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve_relevant_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt):\n\u001b[0;32m---> 91\u001b[0m     docs_with_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search_vector_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlangchain_vector_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_doc_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     keywords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_keywords(prompt)\n\u001b[1;32m     93\u001b[0m     filtered_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contains_keywords_filter(keywords, docs_with_score)\n",
      "File \u001b[0;32m~/data/Dominik/app/RAGPipeline.py:13\u001b[0m, in \u001b[0;36mRAGPipeline._search_vector_db\u001b[0;34m(self, query, vector_db, k)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_search_vector_db\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, vector_db, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m):\n\u001b[1;32m     12\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_query: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m query\n\u001b[0;32m---> 13\u001b[0m     most_similar_docs \u001b[38;5;241m=\u001b[39m \u001b[43mvector_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m most_similar_docs\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/langchain_core/vectorstores.py:323\u001b[0m, in \u001b[0;36mVectorStore.similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return docs and relevance scores in the range [0, 1].\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m0 is dissimilar, 1 is most similar.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    List of Tuples of (doc, similarity_score)\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m score_threshold \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 323\u001b[0m docs_and_similarities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_similarity_search_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    327\u001b[0m     similarity \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m similarity \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, similarity \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities\n\u001b[1;32m    329\u001b[0m ):\n\u001b[1;32m    330\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelevance scores must be between\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m 0 and 1, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocs_and_similarities\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    333\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/langchain_core/vectorstores.py:271\u001b[0m, in \u001b[0;36mVectorStore._similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03mDefault similarity search with relevance scores. Modify if necessary\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03min subclass.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m    List of Tuples of (doc, similarity_score)\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    270\u001b[0m relevance_score_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_relevance_score_fn()\n\u001b[0;32m--> 271\u001b[0m docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [(doc, relevance_score_fn(score)) \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:439\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[0;32m--> 439\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__query_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/langchain_core/utils/utils.py:36\u001b[0m, in \u001b[0;36mxor_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     invalid_group_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(arg_groups[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m invalid_groups]\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExactly one argument in each of the following\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m groups must be defined:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(invalid_group_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     )\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:156\u001b[0m, in \u001b[0;36mChroma.__query_collection\u001b[0;34m(self, query_texts, query_embeddings, n_results, where, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/chromadb/api/models/Collection.py:345\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m include:\n\u001b[1;32m    344\u001b[0m     valid_include\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_query_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_n_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_where\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_where_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m query_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    358\u001b[0m ):\n\u001b[1;32m    359\u001b[0m     query_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_loader(uris) \u001b[38;5;28;01mfor\u001b[39;00m uris \u001b[38;5;129;01min\u001b[39;00m query_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    361\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:143\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/chromadb/rate_limiting/__init__.py:45\u001b[0m, in \u001b[0;36mrate_limit.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Dict[Any, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# If not rate limiting provider is present, just run and return the function.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_system\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mchroma_rate_limiting_provider_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     48\u001b[0m         subject_value \u001b[38;5;241m=\u001b[39m kwargs[subject]\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/chromadb/api/segment.py:724\u001b[0m, in \u001b[0;36mSegmentAPI._query\u001b[0;34m(self, collection_id, query_embeddings, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m id_list \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[1;32m    723\u001b[0m     all_ids\u001b[38;5;241m.\u001b[39mupdate(id_list)\n\u001b[0;32m--> 724\u001b[0m records \u001b[38;5;241m=\u001b[39m \u001b[43mmetadata_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m metadata_by_id \u001b[38;5;241m=\u001b[39m {r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]: r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m records}\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m id_list \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;66;03m# In the segment based architecture, it is possible for one segment\u001b[39;00m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;66;03m# to have a record that another segment does not have. This results in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# the record. In this case we choose to return potentially\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# incorrect data in the form of None.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:143\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/chromadb/segment/impl/metadata/sqlite.py:216\u001b[0m, in \u001b[0;36mSqliteMetadataSegment.get_metadata\u001b[0;34m(self, where, where_document, ids, limit, offset)\u001b[0m\n\u001b[1;32m    212\u001b[0m     q \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mwhere(embeddings_t\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39misin(embeddings_q))\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_db\u001b[38;5;241m.\u001b[39mtx() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# Execute the query with the limit and offset already applied\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/chromadb/segment/impl/metadata/sqlite.py:225\u001b[0m, in \u001b[0;36mSqliteMetadataSegment._records\u001b[0;34m(self, cur, q)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given a cursor and a QueryBuilder, yield a generator of records. Assumes\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mcursor returns rows in ID order.\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m sql, params \u001b[38;5;241m=\u001b[39m get_sql(q)\n\u001b[0;32m--> 225\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m cur_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(cur\u001b[38;5;241m.\u001b[39mfetchone, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    228\u001b[0m group_iterator \u001b[38;5;241m=\u001b[39m groupby(cur_iterator, \u001b[38;5;28;01mlambda\u001b[39;00m r: \u001b[38;5;28mint\u001b[39m(r[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MMLU_domains = ['abstract_algebra', 'anatomy', 'astronomy', 'business_ethics', 'clinical_knowledge', 'college_biology', 'college_chemistry', 'college_computer_science',\n",
    "                'college_mathematics', 'college_medicine', 'college_physics', 'computer_security', 'conceptual_physics', 'econometrics', 'electrical_engineering',\n",
    "                'elementary_mathematics', 'formal_logic', 'global_facts', 'high_school_biology', 'high_school_chemistry', 'high_school_computer_science',\n",
    "                'high_school_european_history', 'high_school_geography', 'high_school_government_and_politics', 'high_school_macroeconomics', 'high_school_mathematics',\n",
    "                'high_school_microeconomics', 'high_school_physics', 'high_school_psychology', 'high_school_statistics', 'high_school_us_history', 'high_school_world_history',\n",
    "                'human_aging', 'human_sexuality', 'international_law', 'jurisprudence', 'logical_fallacies', 'machine_learning', 'management', 'marketing', 'medical_genetics',\n",
    "                'miscellaneous', 'moral_disputes', 'moral_scenarios', 'nutrition', 'philosophy', 'prehistory', 'professional_accounting', 'professional_law',\n",
    "                'professional_medicine', 'professional_psychology', 'public_relations', 'security_studies', 'sociology', 'us_foreign_policy', 'virology', 'world_religions']\n",
    "right_answers = {}\n",
    "question_count = {}\n",
    "bad_format_answers = {}\n",
    "for domain in MMLU_domains:\n",
    "    samples_changed = False\n",
    "    dataset = load_dataset(\"cais/mmlu\", domain, split='test', trust_remote_code=True)\n",
    "    right_answers[domain] = 0\n",
    "    bad_format_answers[domain] = 0\n",
    "    question_count[domain] = len(dataset)\n",
    "    # Prepare sample questions\n",
    "    sample_questions = dataset[-5:]\n",
    "    sample_questions = prepare_sample_questions(sample_questions)\n",
    "    # Prepare sample questions\n",
    "    for idx, question in enumerate(tqdm(dataset)):\n",
    "        ### Inference goes here\n",
    "        if rag_enabled:\n",
    "            torch.cuda.empty_cache()\n",
    "            prompt = question['question']\n",
    "            documents_raw = rag_pipeline.retrieve_relevant_data(prompt)\n",
    "            if len(documents_raw) > 0:\n",
    "                documents_llm = rag_pipeline.format_docs_for_LLM(documents_raw)\n",
    "                RAG_prompt = rag_prompt_template.format(format=output_parser.get_format_instructions(), documents=documents_llm, user_prompt=prompt)\n",
    "                tokenized_context = tokenizer(RAG_prompt, return_tensors=\"pt\").to('cuda')\n",
    "                # Bypass the LLM filter if there are too many tokens to handle\n",
    "                if len(tokenized_context.input_ids[0]) > 5000:\n",
    "                    if len(documents_raw) > 3:\n",
    "                        document_IDs_sanitized = [0,1,2,3]\n",
    "                    else:\n",
    "                        document_IDs_sanitized = [i for i in range(len(documents_raw))]\n",
    "                else:\n",
    "                    model.enable_adapters()\n",
    "                    response = model.generate(tokenized_context.input_ids, pad_token_id=2, attention_mask=tokenized_context.attention_mask, do_sample=False, max_new_tokens=8)\n",
    "                    model.disable_adapters()\n",
    "                    response = response[0][tokenized_context.input_ids.shape[1]:] # Remove the input from the output\n",
    "                    output = tokenizer.decode(response, skip_special_tokens=True)\n",
    "                    document_IDs = output_parser.parse(output)\n",
    "                    document_IDs_sanitized = sanitize_IDs(document_IDs)\n",
    "                if len(document_IDs_sanitized) > 0:\n",
    "                    relevant_documents_raw = select_docs_by_id(documents_raw, document_IDs_sanitized)\n",
    "                    relevant_documents_llm = rag_pipeline.format_doc_for_LLM_no_ids(relevant_documents_raw)\n",
    "                    relevant_documents_llm = \"\\n\" + relevant_documents_llm\n",
    "                if len(relevant_documents_raw) > 0:\n",
    "                    prompt = prepare_prompt(domain, sample_questions, question, relevant_documents_llm)\n",
    "                else:\n",
    "                    prompt = prepare_prompt(domain, sample_questions, question)\n",
    "        else:\n",
    "            prompt = prepare_prompt(domain, sample_questions, question)\n",
    "        print(prompt)\n",
    "        tokenized_context = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "        response = model.generate(tokenized_context.input_ids, pad_token_id=2, attention_mask=tokenized_context.attention_mask, do_sample=False, max_new_tokens=1)\n",
    "        response = response[0][tokenized_context.input_ids.shape[1]:] # Remove the input from the output\n",
    "        answer = tokenizer.decode(response, skip_special_tokens=True)\n",
    "        ### Inference goes here\n",
    "        llm_answer = convert_answer(answer)\n",
    "        if llm_answer == question['answer']:\n",
    "            right_answers[domain] += 1\n",
    "        elif llm_answer == 4:\n",
    "            bad_format_answers[domain] += 1\n",
    "        # After going over approx 50% of questions, select sample questions from\n",
    "        # beginning of the dataset\n",
    "        if not samples_changed and idx > len(dataset) / 2:\n",
    "            sample_questions = dataset[:5]\n",
    "            sample_questions = prepare_sample_questions(sample_questions)\n",
    "            samples_changed = True\n",
    "            torch.cuda.empty_cache()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfea54c-de01-4e21-9078-732a9d8be7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=[\n",
    "    'category',\n",
    "    'question_count',\n",
    "    'right_answers',\n",
    "    'right_answers_percent',\n",
    "    'right_answers_percent_(ignore_bad_format)',\n",
    "    'bad_format_answers',\n",
    "    'bad_format_answers_percent'\n",
    "])\n",
    "for domain in MMLU_domains:\n",
    "    right_answers_percent = round(right_answers[domain] / question_count[domain] * 100, 3)\n",
    "    right_answers_percent_ignore_bad_format = round(right_answers[domain] / (question_count[domain] - bad_format_answers[domain]) * 100, 3)\n",
    "    bad_format_answers_percent = round(bad_format_answers[domain] / question_count[domain] * 100, 3)\n",
    "    row = {\n",
    "        'category': domain, \n",
    "        'question_count': question_count[domain],\n",
    "        'right_answers': right_answers[domain],\n",
    "        'right_answers_percent': right_answers_percent,\n",
    "        'right_answers_percent_(ignore_bad_format)': right_answers_percent_ignore_bad_format,\n",
    "        'bad_format_answers': bad_format_answers[domain],\n",
    "        'bad_format_answers_percent': bad_format_answers_percent\n",
    "    }\n",
    "    results.loc[len(results)] = row\n",
    "results.to_csv(results_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bb41e5-f015-47d8-a141-d934378fb298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
