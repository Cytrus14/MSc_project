{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d12a57d-6d0a-4a31-987c-b478ea20fbb6",
   "metadata": {},
   "source": [
    "# Load dependecies and the setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cf5c675-9241-43e8-bd43-1a507b2ee6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import os\n",
    "import resource\n",
    "import sys\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import CSVLoader, DirectoryLoader\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Project specific modules\n",
    "from scripts import split_documents\n",
    "\n",
    "csv.field_size_limit(sys.maxsize) # Prevents the \"Error: field larger than field limit\" error in CSVLoader\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'True' # Prevent huggingface tokenizers from disabling parallelism\n",
    "\n",
    "# # Limit max RAM usage to 64 GB (may cause out of memory errors)\n",
    "# soft, hard = resource.getrlimit(resource.RLIMIT_AS)\n",
    "# resource.setrlimit(resource.RLIMIT_AS, (64*1024*1024*1024, hard))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9a58ed-337f-4892-9c8c-f5251ff08c61",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4654a17e-aaa3-4c6e-a2d1-92b18613e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_parquet_file_to_csv(parquet_input_file, csv_output_file, columns=None):\n",
    "    \"\"\" Convert the input parquet file into a csv file. If columns is not None, only\n",
    "    specified columns will be copied to the output csv file.\n",
    "\n",
    "    Parameters:\n",
    "    - parquet_input_file (str): input parguet file\n",
    "    - csv_output_file (str): csv output file where the converted data will be saved\n",
    "    - columns (list[str], optional): list of column names to be included in the output csv file\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if columns == None:\n",
    "        df = pd.read_parquet(parquet_file_path)\n",
    "    else:\n",
    "        df = pd.read_parquet(parquet_file_path, columns=columns)\n",
    "    df.to_csv(csv_output_file, index=False)\n",
    "       \n",
    "\n",
    "def split_list(input_list, split_count):\n",
    "    \"\"\"\n",
    "    Split the input_list into split_count sublists\n",
    "\n",
    "    Parameters:\n",
    "    - input_list (list): List to be split\n",
    "    - split_count (int): Number of splits\n",
    "\n",
    "    Yields:\n",
    "    (list): A sublit of elements from input_list\n",
    "    \"\"\"\n",
    "    if split_count > len(input_list):\n",
    "        raise Exception('split_count must be less or equal to input_list length')\n",
    "    sub_list_element_count = len(input_list) // split_count\n",
    "    remaining_elements = len(input_list) % split_count\n",
    "    start = 0\n",
    "    for i in range(split_count):\n",
    "        end = start + sub_list_element_count + (1 if i < remaining_elements else 0)\n",
    "        yield input_list[start:end]\n",
    "        start = end\n",
    "\n",
    "\n",
    "def load_split_docs(csv_input_file, thread_count=8):\n",
    "    \"\"\" \n",
    "    Load the specified csv file, split it into LangChain Documents no longer than\n",
    "    1536 tokens and process them, so they can be used effectively with nomic-embed\n",
    "\n",
    "    Parameters:\n",
    "    - csv_input_file (str): csv input file that will be loaded using the CSVLoader from LangChain\n",
    "    - thread_count (int, optional): number of threads to use during text splitting\n",
    "\n",
    "    Returns:\n",
    "    (list[str]) - list of LangChain Documents created from the input csv file\n",
    "    \"\"\"\n",
    "    #Prepare the csv loader\n",
    "    langchain_loader = CSVLoader(\n",
    "        file_path=csv_input_file,\n",
    "        metadata_columns=['title', 'categories']\n",
    "    )\n",
    "    \n",
    "    # Split the documents using multiple threads and an external splitting script\n",
    "    documents_raw = langchain_loader.load()\n",
    "    documents_raw_sublists = split_list(documents_raw, thread_count)\n",
    "\n",
    "    documents_split_sublists = split_documents.main(documents_raw_sublists, thread_count=thread_count)\n",
    "    documents_split = list(itertools.chain(*documents_split_sublists))\n",
    "\n",
    "    # Prepend 'search_document: ' to each document (required by nomic-embed)\n",
    "    documents_final = []\n",
    "    for doc in documents_split:\n",
    "        documents_final.append(Document(page_content='search_document: ' + doc.page_content, metadata=doc.metadata))\n",
    "    return documents_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e1d03-1d19-4db3-bc16-f3471bd9438b",
   "metadata": {},
   "source": [
    "# Convert parquet files to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84892b4d-d38e-4ffc-bb17-a86047b626ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import psutil\n",
    "parquet_files_dir = os.path.join('data', 'parquet')\n",
    "parquet_file_names = os.listdir(parquet_files_dir)\n",
    "parquet_file_paths = [os.path.join(parquet_files_dir, file_name) for file_name in parquet_file_names] \n",
    "csv_files_dir = os.path.join('data', 'csv')\n",
    "for parquet_file_path in parquet_file_paths:\n",
    "    csv_output_filename = os.path.splitext(os.path.basename(parquet_file_path))[0] + '.csv'\n",
    "    csv_output_file_path = os.path.join(csv_files_dir, csv_output_filename)\n",
    "    # Process each file in a new thread to minimize memory usage\n",
    "    with multiprocessing.Pool(1) as pool:\n",
    "        pool.starmap(convert_parquet_file_to_csv, [(parquet_file_path, csv_output_file_path, ['title', 'text', 'categories'])])\n",
    "    #print(psutil.Process(os.getpid()).memory_info().rss / (1024 * 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76066b-fc4a-4435-afd5-94c39c138cd5",
   "metadata": {},
   "source": [
    "# Initialize objects for data processing, embedding and storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aaab6f1-e9ed-4b77-904e-30d7af350ec2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 2.4.0.dev0, however, your version is 2.3.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-embed-text-v1:\n",
      "- configuration_hf_nomic_bert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c9985dec964db1aa106141d2398c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_hf_nomic_bert.py:   0%|          | 0.00/52.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-embed-text-v1:\n",
      "- modeling_hf_nomic_bert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# langchain_loader = DirectoryLoader(\n",
    "#     os.path.join('data', 'csv'),\n",
    "#     glob='**/*.csv', loader_cls=CSVLoader,\n",
    "#     loader_kwargs={\n",
    "#         'metadata_columns':['title', 'categories']\n",
    "#     },\n",
    "#     use_multithreading=True\n",
    "# )\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "        'trust_remote_code': True\n",
    "    }\n",
    ")\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path='chroma_data')\n",
    "try:\n",
    "    chroma_collection = chroma_client.create_collection(name='english_wikipedia')\n",
    "except chromadb.db.base.UniqueConstraintError as e:\n",
    "    print('Collection already exists: skipping')\n",
    "langchain_vector_db = Chroma(client=chroma_client, embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37a7a5-c9e9-420c-a7f2-8e5c17f581d1",
   "metadata": {},
   "source": [
    "# Load and split the documents, generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79a3d95-f055-4f50-a799-14c2d6751de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f398f22d9b4144cd99fbd88d528c5b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34555 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da68f55233c48ca9a30f9900448a815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32794 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abec07be4484a1a8e334478d0e2cc81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22476 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62823f41a4f4e06bd2a37de0934ce91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1666 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2036cfe40b4749088f082d18452ab5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34033 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1424 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7fc28380bf4c278d847b28d198f16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2223 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2477 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173d4eb4454d45abb3a8f499442ca818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f995465d9f4f14b866bce8969e802b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60841 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dc6c3733d44515852c091eba4ea2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7d874b55ec40a3bb5530d308e229fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09703deb76b74159a79fbe1c390db2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2333 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9b9042751f4d5ea459c5052f50dfd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32769 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb3b24839fc471995e02c69db343078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0d5ca8fcfb4bafab906a297b35160c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8885 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0952ad18937b4f4c90300bd6568d0fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29371 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a5ca757a6343bf824b6a155c8b137f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22846 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1736 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2ccf542f044120b451d3c4935dfed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39730 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5001fbc0074d9ea0470ad40846e334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969932b5ae9b43c18893cd84e755ca4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2918ee1bdc042ee9dbdf22184367c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54713 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1638 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc11f6b032754d7985ab2c398cde4277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440baa645fe4465a9e351f1e7268dcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2658 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b94b92b45542cfacabd093f8a724a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f5124d73c940348227f16548b5a1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ed2615d21b48afb462d4fce7c0233a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6651 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4896 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73988b5a44e4664bbf4d55dc9c0f63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (93379 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5a1eac3bc1411ead804b95563f3a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b79e316c125427d8b0ba31a6be50df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5d 4h 6min 52s, sys: 18h 7min 9s, total: 5d 22h 14min 2s\n",
      "Wall time: 6d 1h 37min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "csv_files_dir = os.path.join('data', 'csv')\n",
    "csv_file_names = os.listdir(csv_files_dir)\n",
    "csv_file_paths = [os.path.join(csv_files_dir, file_name) for file_name in csv_file_names]\n",
    "# Process each file one-by-one in a seperate process to minimize RAM consumption\n",
    "for csv_file in csv_file_paths:\n",
    "    with ProcessPoolExecutor(1) as executor:\n",
    "        future = executor.submit(load_split_docs, csv_file, 48)\n",
    "        documents = future.result()\n",
    "        # Split the documents_final list into multiple sublists to reduce GPU memory consumption\n",
    "        split_count=len(documents) // 20\n",
    "        for docs in tqdm(split_list(documents, split_count), total=split_count):\n",
    "            langchain_vector_db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e59a29-260f-470f-8013-f392c456abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# thread_count = 32\n",
    "# documents_raw = langchain_loader.load()\n",
    "# documents_raw_sublists = split_list(documents_raw, thread_count)\n",
    "\n",
    "# from scripts import split_documents\n",
    "# documents_split_sublists = split_documents.main(documents_raw_sublists, thread_count=thread_count)\n",
    "# documents_split = list(itertools.chain(*documents_split_sublists))\n",
    "\n",
    "# # Delete unnecessary variables to free up memory\n",
    "# del documents_raw\n",
    "# del documents_split_sublists\n",
    "# del documents_raw_sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa4cd9f-59af-4e95-94bf-9729f0f573cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 s, sys: 447 ms, total: 3.26 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# documents_final = []\n",
    "# # Prepend 'search_document: ' to each document (required by nomic-embed)\n",
    "# for doc in documents_split:\n",
    "#     documents_final.append(Document(page_content='search_document: ' + doc.page_content, metadata=doc.metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab32ae6-9f69-4064-be15-3da565c1101f",
   "metadata": {},
   "source": [
    "# Generate document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c195492-8207-4d07-9f14-972d279614ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9541cb84f3a4b258a7fd386d94cd773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 54s, sys: 1min 15s, total: 20min 9s\n",
      "Wall time: 18min\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # Split the documents_final list into multiple sublists to reduce GPU memory consumption\n",
    "# split_count = 1_400_000\n",
    "# for docs in tqdm(split_list(documents_final, split_count), total=split_count):\n",
    "#     langchain_vector_db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c382e0-2db6-425e-90cd-f157b5be9395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(page_content='search_document: text: Xi is the fourteenth letter of the Greek alphabet (uppercase Ξ, lowercase ξ; ), representing the voiceless consonant cluster . Its name is pronounced in Modern Greek, and generally or in English.\"xi\". New Oxford American Dictionary, 2nd Edition. In the system of Greek numerals, it has a value of 60. Xi was derived from the Phoenician letter samekh 20px. Xi is distinct from the letter chi, which gave its form to the Latin letter X. ==Greek == thumb |upright 1.5|left|A joined variant of Ξ (New Athena Unicode font) Both in classical Ancient Greek and in Modern Greek, the letter Ξ represents the consonant cluster /ks/. In some archaic local variants of the Greek alphabet, this letter was missing. Instead, especially in the dialects of most of the Greek mainland and Euboea, the cluster /ks/ was represented by Χ (which in classical Greek is chi, used for ). Because this variant of the Greek alphabet was used in Magna Graecia (the Greek colonies in Sicily and the southern part of the Italian peninsula), the Latin alphabet borrowed Χ rather than Ξ as the Latin letter that represented the /ks/ cluster that was also present in Latin. ==Cyrillic== The Xi was adopted into the early Cyrillic alphabet, as the letter ksi (Ѯ, ѯ). ==Mathematics and science== ===Uppercase=== The uppercase letter Ξ is used as a symbol in various contexts. ==== Pure mathematics ==== * Harish-Chandra\\'s Ξ function in harmonic analysis and representation theory * The Riemann Xi function in analytic number theory and complex analysis ==== Physics ==== * The \"cascade particles\" in particle physics * The partition function under the grand canonical ensemble in statistical mechanics ==== Other uses ==== * Indicating \"no change', metadata={'categories': \"['Greek letters']\", 'row': 7148, 'source': 'data/csv/x.csv', 'title': 'Xi (letter)'}), 0.672990083694458)\n"
     ]
    }
   ],
   "source": [
    "def search_vector_db(query, vector_db, k=10):\n",
    "    most_similar_docs = vector_db.similarity_search_with_score(query, k=k)\n",
    "    print(most_similar_docs[3])\n",
    "\n",
    "search_vector_db(\"search_query: the letter X?\", langchain_vector_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b291c-3e8f-4678-8c02-0a125033d97b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
