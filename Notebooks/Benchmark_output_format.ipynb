{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2c596e-4673-483f-b5ed-46e230c7b7be",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e8d4e6-2f60-4f3b-957b-d11a0fa9482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "import nltk\n",
    "import pandas\n",
    "import spacy\n",
    "import transformers\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.vectorstores import Chroma\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import MistralConfig\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fe0cc-25c5-46cb-9264-bca2eb988768",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c797be-e0ff-487e-89b5-9163e8b1f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(string):\n",
    "    # Extract keywords from the prompt\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    # Extract keywords from the prompt\n",
    "    doc = nlp(string)\n",
    "    keywords = set()\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if not chunk.text.lower().strip() in nltk.corpus.stopwords.words('english'):\n",
    "            text_doc = nlp(chunk.text)\n",
    "            # Remove indirect articles and convert to lowercase\n",
    "            text_words = [token.text for token in text_doc if not token.is_stop]\n",
    "            text = ' '.join(text_words)\n",
    "            # Keyword must be longer than 2 chars to be valid\n",
    "            if len(text) > 2:\n",
    "                keywords.add(text.lower())\n",
    "    # Convert keywords to their singular forms\n",
    "    keywords = list(keywords)\n",
    "    keywords_singular = [lemmatizer.lemmatize(word) for word in keywords]\n",
    "    return keywords_singular\n",
    "\n",
    "def contains_keywords_filter(keywords, docs):\n",
    "    # Filter data by keywords\n",
    "    filtered_data = []\n",
    "    if len(keywords) > 0:\n",
    "        for doc in docs:\n",
    "            el = doc[0].page_content.lower()\n",
    "            if any(keyword in el for keyword in keywords):\n",
    "                filtered_data.append(doc)\n",
    "        return filtered_data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def format_docs_for_LLM(docs):\n",
    "    formated_documents = \"\"\n",
    "    for idx, doc in enumerate(docs):\n",
    "        page_content = \"ID {}:\\n\".format(idx)\n",
    "        page_content += \"Title: {}\\n\".format(doc[0].metadata['title'])\n",
    "        page_content += doc[0].page_content.replace(\"search_document: \", '', 1)\n",
    "        page_content += \"\\n\\n\"\n",
    "        formated_documents += page_content\n",
    "    return formated_documents\n",
    "\n",
    "\n",
    "def test_output_soft(model_output, ids_max_count=4, max_id=7):\n",
    "    # empty list is a valid output\n",
    "    if len(model_output) == 0:\n",
    "        return True\n",
    "    # if the list is not empty, at least one element\n",
    "    # has to be valid\n",
    "    for idx, el in enumerate(model_output):\n",
    "        # if an elemnt is an empty string, continue\n",
    "        if len(el) == 0:\n",
    "            continue\n",
    "        # if an elemnt is an integer in the range [-1, max_id], then it is valid \n",
    "        elif el.isdigit() and int(el) >= -1 and int(el) <= max_id:\n",
    "            return True\n",
    "        # if an element doesn't meet requirements, continue\n",
    "        else:\n",
    "            continue\n",
    "    return False\n",
    "    \n",
    "def test_output_strict(model_output, ids_max_count=4, max_id=7):\n",
    "    valid_els = []\n",
    "    # empty list is a valid output\n",
    "    if len(model_output) == 0:\n",
    "        return True\n",
    "    # single -1 value is a valid output\n",
    "    elif len(model_output) == 1 and model_output[0].isdigit() and int(model_output[0]) == -1:\n",
    "        return True\n",
    "    # returning more ids than ids_max_count constitutes an invalid output \n",
    "    elif len(model_output) > ids_max_count:\n",
    "        return False\n",
    "    # if the list is not empty, and doesn't contain a single -1 value perform further tests\n",
    "    for idx, el in enumerate(model_output):\n",
    "        # if any elemnt is an empty string, then the output is invalid\n",
    "        if len(el) == 0:\n",
    "            return False\n",
    "        # if an elemnt is an integer in the range [0, max_id], then it is valid \n",
    "        if el.isdigit() and int(el) >= 0 and int(el) <= max_id:\n",
    "            valid_els.append(el)\n",
    "        # if any element is invalid, then the whole output is invalid\n",
    "        else:\n",
    "            return False\n",
    "    # if there are duplicated IDs, then the output is invalid\n",
    "    if len(set(valid_els)) != len(model_output):\n",
    "        return False\n",
    "    # if all elements are valid, then the output is valid\n",
    "    return True\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b2eef-5dc5-4793-a4df-697c03b5f132",
   "metadata": {},
   "source": [
    "# Prepare vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a0f5a5-4142-4793-9f27-effedc6a1a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matlab/miniconda3/envs/llm_student_msc/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "        'trust_remote_code': True\n",
    "    }\n",
    ")\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path='chroma_data')\n",
    "langchain_vector_db = Chroma(client=chroma_client, embedding_function=embedding_model)\n",
    "\n",
    "def search_vector_db(query, vector_db, k=512):\n",
    "    query = 'search_query: ' + query\n",
    "    most_similar_docs = vector_db.similarity_search_with_relevance_scores(query, k=k)\n",
    "    return most_similar_docs\n",
    "\n",
    "# Peform initial search to load everything into memory\n",
    "search_vector_db(\"Sample query\", langchain_vector_db, k=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002a5c4-3f68-4e48-bef1-4c221b6689b0",
   "metadata": {},
   "source": [
    "# Initiate the LLM pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522d295-a435-433a-928a-5f24aae65d90",
   "metadata": {},
   "source": [
    "### Option 1 - benchmark the default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee09a50b-4e80-41b4-beab-3c131a233c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102004b99fc84decb09ea3a683305c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", config=MistralConfig, device_map='cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "# pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=8, device=0)\n",
    "# LLM = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e51dda-8e10-477d-b0b5-633058055b7c",
   "metadata": {},
   "source": [
    "### Option 2 - benchmark the fine-tunned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76290c83-3502-4812-8d90-d2cf8a0b7a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfdc27fc2af4eb2839393591a731713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", config=MistralConfig, device_map='cuda')\n",
    "model = PeftModel.from_pretrained(base_model, os.path.join('fine_tuning', 'fine_tuned_models'))\n",
    "model.load_adapter(os.path.join('fine_tuning', 'fine_tuned_models'), 'document_extraction_adapter')\n",
    "model.set_adapter('document_extraction_adapter')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "# pipe = pipeline(task=\"text-generation\", model=base_model, tokenizer=tokenizer, max_new_tokens=8, device=0)\n",
    "# pipe.model = model\n",
    "# LLM = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92455b44-5a85-4e57-9ffd-5c3c601c00ec",
   "metadata": {},
   "source": [
    "# Define other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23f36c3-107b-4757-a2b1-94d39af80d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"<s>[INST] Below is a list of documents. Return up to 4 IDs of documents most useful for solving the user_prompt. If no documents are relevant, output -1. {format}. \n",
    "\n",
    "<documents>\n",
    "{documents}\n",
    "</documents>\n",
    "\n",
    "user_prompt: {user_prompt}\n",
    "\n",
    "[/INST]IDs: \"\"\"\n",
    "\n",
    "test_data = pandas.read_csv(os.path.join('data', 'benchmarks', 'RAG_test_data.csv'))\n",
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1335c9fd-4e2c-4cda-bce1-8ae25e8fb968",
   "metadata": {},
   "source": [
    "# Run the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be24816-b2b5-4bd7-840c-e2515b36209b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a43c2e889d4e1e89ba1ff1c27bfe45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_count = len(test_data)\n",
    "valid_outputs_standard = 0\n",
    "valid_outputs_strict = 0\n",
    "invalid_outputs_list = []\n",
    "for idx, row in tqdm(test_data.iterrows(), total=sample_count):  \n",
    "    user_prompt = row['text']\n",
    "    docs_with_score = search_vector_db(user_prompt, langchain_vector_db)\n",
    "\n",
    "    keywords = extract_keywords(user_prompt)\n",
    "    filtered_docs = contains_keywords_filter(keywords, docs_with_score)\n",
    "    filtered_docs = filtered_docs[:8]\n",
    "    documents = format_docs_for_LLM(filtered_docs)\n",
    "\n",
    "    # prompt = PromptTemplate.from_template(prompt_template)\n",
    "    # chain = prompt | LLM\n",
    "    # response = chain.invoke({'format':output_parser.get_format_instructions(), 'documents': documents, 'user_prompt': user_prompt})\n",
    "    # converted_response = output_parser.parse(response)\n",
    "    \n",
    "    RAG_prompt = prompt_template.format(format=output_parser.get_format_instructions(), documents=documents, user_prompt=user_prompt)\n",
    "    tokenized_context = tokenizer(RAG_prompt, return_tensors=\"pt\").to('cuda')\n",
    "    response = model.generate(tokenized_context.input_ids, attention_mask=tokenized_context.attention_mask, do_sample=False, max_new_tokens=8)\n",
    "    response = response[0][tokenized_context.input_ids.shape[1]:] # Remove the input from the output\n",
    "    output = tokenizer.decode(response, skip_special_tokens=True)\n",
    "    document_IDs = output_parser.parse(output)\n",
    "    if test_output_soft(document_IDs):\n",
    "        valid_outputs_standard += 1\n",
    "        if test_output_strict(document_IDs):\n",
    "            valid_outputs_strict += 1\n",
    "    else:\n",
    "        invalid_outputs_list.append(document_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9eb04a-0644-44f5-ae30-749204cd9c52",
   "metadata": {},
   "source": [
    "# Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccbcda41-9f64-44db-abaf-eb06ab68d0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid outputs: 99.11111111111111%\n",
      "Valid outputs (strict): 13.777777777777779%\n",
      "Invalid outpus:\n"
     ]
    }
   ],
   "source": [
    "print('Valid outputs: {}%'.format(valid_outputs_standard/sample_count * 100))\n",
    "print('Valid outputs (strict): {}%'.format(valid_outputs_strict/sample_count * 100))\n",
    "\n",
    "print('Invalid outpus:')\n",
    "#print(invalid_outputs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962963e-faf7-49b7-9c89-c85f51555a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
